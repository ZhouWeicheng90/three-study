### 纹理（贴图）

#### 使用基础

```js
TextureLoader // 先new再加载，可以重复使用加载器
ImageLoader  // 加载图片后，直接创建纹理：
	var texture = new THREE.Texture(img);  // 必须设置 texture.needsUpdate = true; 纹理才可用
ObjectLoader
	loader.load('model.json',function (obj) {...}  // 得到的obj是一个可以加入scene的Object3D
    // 需要json遵循 three.js规则
// 同步加载：
    var texture = textureLoader.load(url);  // 另外两个loader可以这样吗？
    // 经过测试，这样加载最开始的纹理时黑色的，过一会等纹理正在加载好了，才是正常的。                                              
// canvas纹理：
let texture = new THREE.CanvasTexture(canvas);  // canvas可以不在document中！ 可以使用canvas的2d功能！
// video纹理
let texture = new THREE.VideoTexture(video);  // 普通的 <video/>                                             
                                             

material.map
// 使用：
// 材质的 map 属性设为纹理 texture
// 一个已经画出来了的模型可以动态修改其纹理:
	mesh.material.map = texture2; // 需要再次调用render
// color设置 会和纹理综合作用！！！                                            


纹理坐标:
// 将图片的像素位置，映射到 [-1,1]*[-1,1]的区间上，然后设置几何体每个顶点对应的图片坐标（即纹理坐标）
// 纹理是一个独立的对象，几何体对象的每个顶点有对应的纹理坐标（默认就是自身的归一化的坐标）

设置顶点对应的纹理：
// Geometry 的 faceVertexUvs : 
	// geometry.faceVertexUvs[0][0]=[v2_1, v2_2, v2_3]  
	// 每个v2是 new THREE.Vector2(0.2,0.2)这样的 x,y都在[0,1]之间。
	// 每个face有3个顶点，所以有3个纹理坐标与之对应
// BufferGeometry 的 attributes.uv
	// geometry.attributes.uv = new THREE.BufferAttribute(arr, 2);
	// arr就是 [x1,y1,x2,y2,…………]这样的数组


```

#### 数组材质

```js
var mesh = new THREE.Mesh(geometry, materialArr);
	// 多个材质，但每个三角形绘制时只能使用一个
	// 这由每个face的materialIndex决定
	geometry.faces[4].materialIndex = 1;
	bufferGeometry.groups // bufferGeo由groups配置决定，这个配置较灵活，例：
	bufferGeometry.groups[i] = {start:0,count:9,materialIndex:1} // 表示从第0个顶点开始，一共9个顶点（即3个三角形）采用第1个材质。

// 内置的几何体，如box，sphere 都有默认的materialIndex设置！（立方体6个面，12个三角形都设了）
```

#### 纹理的变换处理

纹理可不只是傻傻的加载一张图片就可以了！

```js
// 重复列阵：
texture.wrapS = THREE.RepeatWrapping;  // 设置水平方向的重复方式
texture.wrapT = THREE.RepeatWrapping;
texture.repeat.set(4, 2);   // 水平方向重复4个，垂直2个（4*2）
texture.repeat.x = 20;
texture.repeat= new THREE.Vector2(20,1)

// 偏移
texture.offset = new THREE.Vector2(0.3, 0.1)
texture.offset.set(0.25,0.25);

// 偏移与列阵同时设置时，注意偏移的始终是单个图片，列阵不过是重复，列阵不是产生新的图片！
```

```js
texture.rotation = Math.PI / 3;
texture.center.set(0.5, 0.5); // 设置纹理的旋转中心，默认(0,0)
```

### 常用贴图（1+3种）

除了上面提到的map，还有normalMap、bumpMap、specularMap。

#### 凸凹纹理和法线纹理

普通的纹理对象，配置在不同的属性上，表达的信息不同

```js
// 法线纹理：图片的rgb分量表示的是法线xyz，从而图片描述了物体表面的凸凹细节！
normalMap: normalMap,
normalScale: new THREE.Vector2( 0.8, 0.8 )  // 表示深浅程度

// 凸凹纹理： 图片像素的灰度值 描述物体表面的凸凹细节！
bumpMap: bumpMap,
bumpScale: 12   // 表示深浅程度

// 注意：
// 凸凹纹理，法线纹理，在 MeshBasicMaterial和MeshLambertMaterial中不存在！！存在于具有高光属性的材质中！
// 这两个纹理 都是表达表面凹凸细节的，但显然表达方向的法线贴图信息更丰富。
// 如果写了两个将采用法线纹理，忽略凸凹纹理。
```

#### 高光贴图

```js
// 高光材质 specular属性 描述了镜面反射能力，但如果物体表面不同地方的镜面反射能力不同，如人脸，就要借助高光贴图了：
specularMap: specularMap   // 用纹理的rgb值 表达镜面反射的能力
```
### 其他贴图

#### 阴影贴图（lightMap)

``` js
// 设置阴影，通常无需设置
lightMap: textureLight  // 设置的是【阴影区域的纹理】，所以通常在 receiveShadow 的地方设置！
// 阴影贴图 和 普通的贴图基本一样，不过相反的是：光线越弱，贴图越明显。

第2套纹理坐标:
// 贴图就要有纹理坐标，阴影纹理坐标就是【第2套纹理坐标】
// 通常可以直接采用第一套纹理坐标(用于普通纹理，法线纹理等) 作为阴影的纹理坐标，于是通常这么设置：
bufferGeometry.attributes.uv2 = bufferGeometry.attributes.uv;  
geometry.faceVertexUvs[1] = geometry.faceVertexUvs[0];  
```
#### 环境贴图

```js
// 环境纹理 由6张图片 组成： 
const cubeTexture = new THREE.CubeTextureLoader()
  .setPath("/person/")
  .load([
    "posx.jpg",   // 看向x轴正方向的图片
    "negx.jpg",   // 看向x轴负方向的图片
    "posy.jpg",
    "negy.jpg",
    "posz.jpg",
    "negz.jpg"
  ]);


// 加入环境：
scene.background = cubeTexture;  
// 3d场景有了环境，就像VR一样。  
// 注意：前提是你的相机是 perspective模式的，不能是orthographic的


// 这样配置材质，让反光材质，反射出周围的环境！！
envMap: cubeTexture    // 让环境的光 反映到物体上（不需要则不用配置）

```

#### 数据生成纹理（DataTexture）

示例：

``` js
function generateMaterial(width = 32, height = 32) {
  const size = width * height; //像素大小
  const data = new Uint8Array(size * 4); // size*4：rgba 每个像素4个字节
  for (let i = 0; i < size * 4; i += 4) {   
    data[i] = 255 * Math.random();
    data[i + 1] = 255 * Math.random();
    data[i + 2] = 255 * Math.random();    
    data[i + 3] = 255 * 0.5;
  }
  const texture = new THREE.DataTexture(data, width, height, THREE.RGBAFormat);
  texture.needsUpdate = true;
  var material = new THREE.MeshPhongMaterial({
    map: texture, 
    transparent: true //注意，这个一定要设，否则前面生成的透明度无效
  })
  return material;
}

```

### 相机与渲染

#### 相机深入

![image-20201217193203840](E:\MGh\three-study\image-20201217193203840.png)

机械、工业设计领域常常采用正投影(平行投影), 大型游戏场景往往采用透视投影(中心投影)

``` js
new OrthographicCamera( left, right, top, bottom, near, far )   // 视区形成一个长方体
new PerspectiveCamera( fov, aspect, near, far )    // 视区形成一个长方椎体， fov 0-180度，一般45-90，默认50
// 注意：超出视区的物体，都将无法显示！


.matrixWorldInverse  // 相机对象的视图矩阵 的逆矩阵。---相机视角 【这个矩阵 由相机的位置+相机的lookAt 决定】
		.position
		.lookAt(vec3)
.projectionMatrix  // 投影映射矩阵 --- canvas坐标，归一化  【这个矩阵 由构造相机时 决定】
// 实际上 每个物体的绘制 最终都是要 *matrixWorldInverse*projectionMatrix 的


.projectionMatrixInverse // projectionMatrix 的逆矩阵

```

#### 自适应渲染

窗口变了，如何让渲染自适应？

``` js
window.onresize = function(){
    ... ...
}
```
分三步（修改渲染器，修改相机参数，更新投影矩阵）：

```js
renderer.setSize(window.innerWidth,window.innerHeight);

// 正投影相机：
camera.left = -W/2;
camera.right = W/2;
camera.top = H/2;
camera.bottom = -H/2;
// 透视投影相机：
camera.aspect = window.innerWidth/window.innerHeight;

camera.updateProjectionMatrix ();
```

### 精灵模型

创建精灵模型对象不需要创建几何体对象`Geometry`，可以理解为已经内部封装了一个平面矩形几何体`PlaneGeometry`，不同的是精灵模型的矩形平面会始终平行于Canvas画布

```js
SpriteMaterial
// 常见属性： color，map，等
// 特有属性：rotation  
```

在使用透视投影相机对象的时候，精灵模型对象显示的大小和网格模型一样受距离相机的距离影响，也就是距离越远，显示效果越小。

``` js
sprite.scale.set(10, 10); // 设置精灵大小用scale (缩放z无意义)
sprite.position.set(0, 0, 900);
```

在三维场景中把精灵模型作为一个模型的标签，标签上可以显示一个写模型的信息

足够多的精灵模型对象，构建一个粒子系统，来模拟一个下雨、森林、或下雪的场景效果

``` js
// 淡化远处的sprite：
let { x: cx, y: cy, z: cz } = camera.position;
let { x, y, z } = sprite.position;
let dis = Math.sqrt(Math.pow(x - cx, 2) + Math.pow(y - cy, 2) + Math.pow(z - cz, 2));
sprite.material.opacity = 1 - dis / maxtDisToSee;  // maxtDisToSee应该是一个独立的参数(可视范围)

// 模拟下雨或下雪，
// 在一个盒子中创建 1000 个sprite，位置随机。 边界位置：Lelf,Rright, Top,Bottom, Front,Back
// 然后对每个精灵
sprite.translateY(-0.4); 
if (sprite.position.y <= -H * 0.5) {
      sprite.position.setY(H * 0.5);
}

// 改变方向和视角：借助父元素group，移动，旋转！
group.translateY(0.2 * Top);  // 视角，底部加高
group.rotateZ(Math.PI/3)
group.rotateX(-Math.PI/6)
```



### 动画

#### 定义动画：

##### 定义keyframe（关键帧）和animationClip（动画剪辑）

在加载外部模型的时候，这通常已经加载好了。

```js
mesh.name = "box";  // 定义都是基于name的：

var times = [0, 20]; //关键帧时间数组，离散的时间点序列，单位s
var values = [0, 0, 0, 150, 0, 0]; //与时间点对应的值组成的数组：0时刻对应位置0, 0, 0   20时刻对应位置150, 0, 0
var posKF = new THREE.KeyframeTrack("box.position", times, values);// 创建了一个移动动画

// 类似的：
var colorKF = new THREE.KeyframeTrack("box.material.color", [10, 20], [1, 0, 0, 0, 0, 1]);  // 颜色动画，注意（box.material.color)
var scaleKF = new THREE.KeyframeTrack("box.scale", [0, 20], [1, 1, 1, 3, 3, 3]);


var duration = 20;  // 单位：s
// duration决定了默认的播放时间，一般取所有帧动画的 最大时间
// duration偏小，帧动画数据无法播放完；偏大，播放完帧 剩余的空白时间会 保持最终状态；
// 多个关键帧 创建一个剪辑clip对象， 命名"animationClip01"
var clip = new THREE.AnimationClip("animationClip01", duration, [posKF,colorKF,scaleKF]);

clip.duration = 15; // 中途设置
```

##### 混合器混入动画（AnimationMixer + Clock）

``` js
var mixer = new THREE.AnimationMixer(scene);  // 除了scene也可以写group等parentObject
var animationAction = mixer.clipAction(clip).play();   // 注意：这个play方法是AnimationAction对象的！
// 以上两句就将动画加入到渲染种类，但还不够！

// 帮助混合器追踪时间：
var clock = new THREE.Clock(); 
// 通常在 RAF 中渲染，每次渲染前要告诉混合器时间：
mixer.update(clock.getDelta()); // 更新混合器相关的时间，其中clock.getDelta()方法获得两帧的时间间隔
// 注意：不同的动画，clock不能共用！clock内部有一个时间缓存，第一个动画使用能返回正确的时间差，后续得到的时间差将是0，所以不能共用clock。

```

##### 调整动画细节：

``` js

animationAction.timeScale = 2; // 可以调节播放速度,默认1  实际播放时间未 duration/timeScale
animationAction.loop = THREE.LoopOnce; //不循环播放； THREE.LoopRepeat（默认。无限循环）；THREE.LoopPingPong（来回循环）;
animationAction.paused = true; // 暂停动画（设置false，取消暂停，继续动画）

animationAction.clampWhenFinished = true; // 动画结束后，暂停在最后一帧播放的状态，默认fasle，表示回到开始状态
// 显然无限循环的动画不会结束，设置这个无意义。

animationAction.time = 10; // 设置首次播放的开始时间
```

综合示例 —— 让动画定格到指定时间 10s：

```js
animationAction.loop = THREE.LoopOnce;   // 前提
animationAction.clampWhenFinished = true;   // 前提
AnimationAction.time = 10; 
clip.duration = AnimationAction.time;

// 或
AnimationAction.paused=true;
AnimationAction.time = 10;

// 两者都有一个前提，就是开启clock更新:  mixer.update(clock.getDelta())
```



#### 对于加载的外部模型：

```js
// obj作为混合器的参数，可以播放obj包含的帧动画数据
mixer = new THREE.AnimationMixer(obj);
// obj.animations[0]：获得剪辑clip对象
// // 剪辑clip作为参数，通过混合器clipAction方法返回一个操作对象AnimationAction
var AnimationAction = mixer.clipAction(obj.animations[0]);
AnimationAction.play();

```

#### 模型json示例：

``` json
"object": {
  // 绑定动画的模型名称Box
  "name": "Box",
...
},
// 动画数据
"animations": [{
  "name": "default",
  "fps": 24,
  "tracks": [
    // 位置变化关键帧
    {
    "type": "vector3",
    "name": "Box.position",
    "keys": [{
      "value": [0, 0, 0],
      "time": 0
    }, {
      "value": [-100, 0, 0],
      "time": 50
    },...]
  },
  // 角度变化关键帧
  {
    "type": "quaternion",
    "name": "Box.quaternion",
    "keys": [{
      "value": [0, 0, 0, 0],
      "time": 0
    },...]
  },
  // 颜色变化关键帧
  {
    "type": "color",
    "name": "Box.material.color",
    "keys": [{
      "value": [1, 0, 0, 1],
      "time": 20
    }, ...]
  }]
}]
```

### 骨骼动画和变形（未完成）

```js
Bone  // 关节
	bone1.add(bone2);
	bone2.add(bone3);   // 构建骨关节的系统----层级关系
	bone2.position.y = 60;

Skeleton  // 骨架
	var skeleton = new THREE.Skeleton([bone1, bone2, bone3]); //创建骨骼系统

SkinnedMesh  // 要和关节骨架关联起来，用普通的geometry和mesh类material就可以创建
    skinnedMesh.add(bone1); //根骨头关节添加到网格模型
	skinnedMesh.bind(skeleton); //网格模型绑定到骨骼系统
// 骨骼动画，要通过 skinnedMesh实现，其实就是操作bone的动画

geometry中有skinWeights（权重）和skinIndices（索引）
//  表达：几何体的顶点位置是如何受骨关节运动影响的，骨关节运动了，皮肤（即蒙皮）不同区域变形程度不同   
//  geometry 每个顶点可以有4个bone影响，这就是为什么两者都是一个Vector4数组了。
//  其中skinWeights每个分量的值是0-1之间，当设置为0.5时，将产生50％的影响。如果只有一个骨关节Bone与顶点关联，那么你只需要设置第一个分量，其余分量的可以忽略并设置为0
//  skinIndices，每个分量表示bone的索引，描述受到哪4个关节的影响。   
```

变形：

```js
morphTargets // 存放 顶点。一般在外部资源中已存在
// 变形的本质是 多组顶点数据 （两组顶点的过渡，代表顶点位置的过渡，产生动画）

mesh.morphTargetInfluences[1] // 变形目标影响权重，值在 0-1 之间。
// 下标1表示morphTargets[1]代表的顶点形状
```

### 音频

#### 声音与3D声音

``` js
// 各api 本质上是对原生Web Audio API的封装
AudioLoader  // 对FileLoader的封装，加载音频资源 得到AudioBuffer数据！

let audioBuffer = await new Promise(resolve => {
  new THREE.AudioLoader().load("/robot/333.mp3", function(buffer) {
    resolve(buffer);
  });
});

AudioListener  // 听声音的地方 
var listener = new THREE.AudioListener();
// 在创建播放器时，必须传入一个listener！
// 如果要构建3d场景中的模型，那么听声音的位置就是camera了，这时需要加入：
camera.add(listener);     // 【注1】

播放器 // 有2中，有位置的和没有位置的：
// Audio
var audio = new THREE.Audio(listener);
// PositionalAudio
var audio = new THREE.PositionalAudio(listener);
mesh.add(audio);   // 【注2】 PositionalAudio必须要加入到某一个模型上

// 【注1】和【注2】在构建3d场景音效时，缺一不可！听的位置，和播放的位置！

// 播放器的操作：
audio.setBuffer(audioBuffer);
audio.play();  // stop停止、pause暂停
audio.setVolume(0.5);
audio.setLoop(true);
audio.setRefDistance(100); //参数值越大,声音越大    
```

#### 声音可视化：

``` js
let analyser = new THREE.AudioAnalyser(audio, 2*N);   // N必须是2^n这样的数, 这在下方获取波形数据时，会得到N个数据

// 然后在每个 raf 中：
var arr = analyser.getFrequencyData();   // arr有N个数据，但只有前 N/4 个是变动较大的数据，后面的基本一直是0
// var num = analyser.getAverageFrequency()  // 这是直接获取前者的平均数
// 所以只取前 N/4 个数据
let volumes = Array.from(arr.slice(0, N / 4));        
```

#### 监听音频播放结束

```js
// 经过测试 audio.isPlaying, audio.onEnded 并不能完美的和实际情况一直
// audio.duration 也是空的，除非你手动设置：
audio.duration = audioBuffer.duration;

audio.play();  // isPlaying 变为true
setTimeout(() => {
  audio.stop();   // 这样 isPlaying 才变回false
}, audio.duration * 1000);

// 以下不靠谱：
audio.onEnded = ()=>{   // 可能监听不到 onEnded
    console.log(audio.isPlaying) // 可能仍然是true
}
```



### 加载外部模型

#### 使用阴影，动画变形

设置mesh的阴影，要用迭代！

``` js
let mesh = gltf.scene;
mesh.castShadow = true;   // 简单这样设置是错误的！ 外部模型可能是很多mesh的组合！！！需要全部设置！

// 时刻以组合的方式 思考问题！
mesh.traverse(node => {
  if (node.isMesh) {
    node.castShadow = true;
  }
});
```

加载阴影的另一个关键是设置 光的shadow.camera!

动画和morph

``` js
动画 // 都在 gltf.animations 中，很好找
morph  // 由于是嵌套到内部的material和geometry中，这个有点难找。 可以通过 mesh的name + 直觉判断
```

#### .stl  .obj  .mtl

> 所有文件加载后 json化，打印到console中，然后复制到json文件中，尝试加载解析json文件
>
> 
>
> `.stl`格式的三维模型不包含材质Material信息，只包含几何体顶点数据的信息，你可以简单地把stl文件理解为几何体对象Geometry，
> [三个顶点 + 一个三角形面的法向量 为一组]
>
> 基本所有的**三维软件**都支持导出`.stl`格式的三维模型文件。STLLoader 加载器，直接提取信息转化为BufferGeometry。
> 定制加载器，很有必要学习参考 STLLoader。
>
> 
>
> `.obj`和`.stl`文件一样，包含的信息都是几何体顶点相关数据。  OBJLoader
>
> 通常三维软件导出时会有 .obj + .mtl(材质文件)。   MTLLoader
>
> 材质文件`.mtl`包含的是模型的材质信息，比如颜色、贴图**路径**等。如果路径有问题，可能会无法加载。
>
> 关于路径，注意防止乱码，可以打开文件修改。
>
> 
>
> > 解析obj文件，得到的是一个完整的mesh，里面的material 也是有的 ？？？！还是默认的？
> >
>  ``` js
>  objLoader.setMaterials(materials);   // materials 由 MTLLoader 加载得到
>  objLoader.load(...)
>  ```
>
> obj文件可以包含多个网格模型对象！
>
> ``` js
> objLoader.load('./多个模型/model.obj',function (obj) {  
>   scene.add(obj);  
>   obj.scale.set(20,20,20);  
>   obj.children[0].material.color.set(0xff0000);// 设置其中一个网格模型的颜色
> })
> ```
>
> `.obj`文件不包含场景的相机[Camera](http://www.yanhuangxueyuan.com/threejs/docs/index.html#api/zh/cameras/Camera)、光源[Light](http://www.yanhuangxueyuan.com/threejs/docs/index.html#api/zh/lights/Light)等信息，不能导出骨骼动画、变形动画，
>
> 要导出这些信息可以选择 `.fbx`、`.gltf` 等格式。

#### .fbx

stl、obj都是静态模型，不可以包含动画，fbx除了包含几何、材质信息，可以存储骨骼动画等数据。

```js
FBXLoader
// 解析的结果中 animations 是动画信息（骨骼动画 也是动画）
```

### 点击 -- Raycaster

```js
// scene内部的模型和鼠标交互，关键就是识别鼠标位置是否为某一个模型！
const point = new THREE.Vector2(-1, 1);
canvas.onclick = e => {        
  point.x = (e.offsetX * 2) / W - 1;    // 这里用的offset坐标，是相对于canvas的坐标
  point.y = 1 - (e.offsetY * 2) / H;    // 坐标归一化 y要翻转！
};


const raycaster = new THREE.Raycaster();
// 下方代码在 raf 中：
raycaster.setFromCamera(point, camera);   
const intersects = raycaster.intersectObjects(scene.children, true);    
// 第二个参数true表示递归。默认false，只会遍历scene的第一层children
// 得到的 intersects 是细小的“零部件”模型，怎么判断是否为某个具体的物体（如机器人robotMesh）？
let isTouchRobot = false;
for (let i = 0; i < intersects.length && !isTouchRobot; i++) {
  robotMesh.traverse(node => {
    if (!isTouchRobot && node === intersects[i].object) {
      isTouchRobot = true;
    }
  });
}
if (isTouchRobot) {
    console.log('点击了机器人')
}
```

上方代码仅仅是识别点击了物体，但是还要做处理。

首先，point是一个静态数据，如果你不设置的话物体将一直处于被点击的状态。

其次raf的触发频率较高，如果不控制的话，就相当于极快的速度连续点击

``` js
if (isTouchRobot && !clickHandleing) {    // clickHandleing  的状态控制很重要
    clickHandleing = true
    ... // handle click code    
    onHandleEnd = ()=>{        
        ... // 还原点击前的现场
        point.set(-1, 1);     // 这个设置很重要。
        clickHandleing = false;
    }
}
```

### 文字

``` js
文字部分 4 5节
```








```
webgl_skinning_simple.html
webgl_animation_skinning_additive_blending.html
```



### API 补充

``` js
THREE.RGBFormat   // 对应于 gl.RGB
THREE.RGBAFormat   // 对应于 gl.RGBA

HemisphereLight // 半球光，不能产生阴影的光源。天空色-地面色 的渐变光，也能产生立体效果

Fog  // new 一个Fog，然后赋给 scene.fog

// 通过平均面法线来计算顶点法线，效果更光滑
  geometry.computeVertexNormals();


AudioContext  // 在AudioListener和AudioLoader 类中被使用.  构建细致的VR体验可能需要


LightProbe:  // 光照探针，本身不发光，模拟周围的的环境，高保真
/**
http://localhost:8080/examples/#webgl_lightprobe
http://localhost:8080/examples/#webgl_lightprobe_cubecamera
*/

RectAreaLight  // 构建一个发光的矩形，一个窗户……
//  http://localhost:8080/examples/#webgl_materials_envmaps_parallax
//  http://localhost:8080/examples/#webgl_lights_rectarealight

```

```
https://sketchfab.com/3d-models?date=week&features=downloadable&sort_by=-likeCount
enne5w4@126.com  3dmodelzhou
```



### 待强化



spotLight和directionalLight的方向该怎么设置？？———— 手电筒，发光镜

LightHelper的设置



高光材质的使用（透明度玻璃管？？）

纹理的旋转

http://localhost:8080/examples/#webgl_materials_shaders_fresnel   // 小球

http://localhost:8080/examples/#webxr_vr_sandbox  // 反光镜

http://localhost:8080/examples/#physics_ammo_terrain // 曲面上滚动的小球

